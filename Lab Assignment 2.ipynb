{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28da2f-a5d9-4417-8416-6072b8d8ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUR AFIQAH NAJIHAH BINTI MOHD NASIR\n",
    "#IS01083539\n",
    "\n",
    "# !pip install pandas numpy nltk scikit-learn\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50330956-82d4-43c3-8eca-14c287f4a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  I have bought several of the Vitality canned d...   \n",
      "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
      "2  This is a confection that has been around a fe...   \n",
      "3  If you are looking for the secret ingredient i...   \n",
      "4  Great taffy at a great price.  There was a wid...   \n",
      "\n",
      "                                        Cleaned_Text  \n",
      "0  bought several vitality canned dog food produc...  \n",
      "1  product arrived labeled jumbo salted peanutsth...  \n",
      "2  confection around centuries light pillowy citr...  \n",
      "3  looking secret ingredient robitussin believe f...  \n",
      "4  great taffy great price wide assortment yummy ...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset \n",
    "df = pd.read_csv(r'C:\\Users\\Win10\\OneDrive\\Documents\\UNITEN\\Txt Analytics\\Lab Assignment 2\\Amazon Fine Food\\Reviews.csv')\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert timestamps\n",
    "df['Time'] = pd.to_datetime(df['Time'], unit='s')\n",
    "\n",
    "# Remove punctuation, stopwords, and unnecessary characters\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['Cleaned_Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "print(df[['Text', 'Cleaned_Text']].head())  # Show original vs cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82a87ad-bbd0-4c84-8cdf-d4c57d719207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF features: (568454, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Transform text data into numerical features\n",
    "X = vectorizer.fit_transform(df['Cleaned_Text'])\n",
    "\n",
    "print(\"Shape of TF-IDF features:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de21ff30-ab65-4dea-afec-6305a2ba3fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: (454763, 5000)\n",
      "Testing samples: (113691, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Assign labels (positive = 1, negative = 0)\n",
    "y = df['Score'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training samples:\", X_train.shape)\n",
    "print(\"Testing samples:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233aa2e-78fc-403e-9be8-5e50ace94a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained.\n",
      "Na誰ve Bayes model trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Na誰ve Bayes': MultinomialNB(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Train each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f273e0-0524-4fc7-89b2-da3238097d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46121f67-a055-42b9-8e19-e835db9be770",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this assignment, sentiment classification was performed using Logistic Regression, Na誰ve Bayes, and SVM models. \n",
    "Na誰ve Bayes is lightweight and fast, making it ideal for simple text classification. However, it assumes feature \n",
    "independence, which may limit performance. Logistic Regression provides reliable results but struggles with complex \n",
    "sentence structures. SVM offers high accuracy, particularly for text classification, but requires more computational \n",
    "resources. Future improvements could involve fine-tuning deep learning models like BERT to enhance sentiment \n",
    "context understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf658e-76af-4e22-86fa-854262485259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the correct directory\n",
    "df.to_csv(r\"C:\\Users\\Win10\\OneDrive\\Documents\\UNITEN\\Txt Analytics\\Lab Assignment 2\\Amazon Fine Food\\Processed_Reviews.csv\", index=False)\n",
    "print(\"File saved successfully!\")\n",
    "\n",
    "# List files in the folder\n",
    "print(\"Files in directory:\", os.listdir(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcd9d2-6bba-494b-9f23-35f878b1f0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
